{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from categorization import fscore\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy\n",
    "import time\n",
    "#For each pair in df_simil_rates, calculate distance and append in the DataFrame\n",
    "def update_df(dataframe,elem_num,embeddings):\n",
    "    l=[]\n",
    "    #n=0\n",
    "    for i in range(len(dataframe)):\n",
    "        word1=dataframe.iloc[i]['word1']\n",
    "        word2=dataframe.iloc[i]['word2']\n",
    "        \n",
    "        #calculate distance\n",
    "        try:\n",
    "            pos_word1 = elem_num[word1]\n",
    "            pos_word2 = elem_num[word2]\n",
    "        except KeyError:\n",
    "            #n+=1\n",
    "            pass\n",
    "        \n",
    "        #dis = torch.sqrt(sum((embeddings[pos_word1]-embeddings[pos_word2])**2))\n",
    "        cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "        dis=cos(embeddings[pos_word1],embeddings[pos_word2])\n",
    "        #print(word1,word2,dis)\n",
    "        l.append(dis.item())\n",
    "    dataframe['dist']=l\n",
    "    #print(n)\n",
    "    return dataframe\n",
    "\n",
    "#Finally, we calculate Spearman's rho\n",
    "def rho(dataframe,elem_num,embeddings,rtype):\n",
    "    dataframe = update_df(dataframe,elem_num,embeddings) \n",
    "    #Calculate d\n",
    "    if rtype == 'semantic':\n",
    "       a=dataframe['semantic'].tolist()\n",
    "       b=dataframe['dist'].tolist()\n",
    "    elif rtype == 'visual':\n",
    "       a=dataframe['visual'].tolist()\n",
    "       b=dataframe['dist'].tolist()\n",
    "    \"\"\"\n",
    "    #Protection against NaN\n",
    "    for i,elem in enumerate(b):\n",
    "        b[i]+=0.000000000000000000000000001*i\n",
    "        print(b[i])\n",
    "    \"\"\"\n",
    "    #Calculate rho\n",
    "    coef, p= scipy.stats.spearmanr(a,b,axis=0)\n",
    "    return coef, p\n",
    "\n",
    "def evaluate(embeddings):\n",
    "#EVALUATE\n",
    "#from spearmansrho import rho\n",
    "    df_simil_rates = pd.read_csv('./data/similarity-ratings.tsv',sep='\\t')\n",
    "    num2elem=np.load('./data/Visual_att_row_keys.npy')\n",
    "    ele2num = {a:b for b,a in enumerate(num2elem)}\n",
    "\n",
    "    #sem, p =rho(df_simil_rates,ele2num,embeddings,'semantic')\n",
    "    #print('Semantic similarity is '+str(sem))\n",
    "###############################################################\n",
    "\n",
    "\n",
    "    sem,p=rho(df_simil_rates,ele2num,embeddings,'semantic')\n",
    "    print('Semantic similarity is '+str(sem))\n",
    "    \n",
    "    sem,p=rho(df_simil_rates,ele2num,embeddings,'visual')\n",
    "    print('Visual similarity is '+str(sem))\n",
    "\n",
    "def evaluate_cat(embeddings):\n",
    "#EVALUATE\n",
    "#from spearmansrho import rho\n",
    "    num2elem=np.load('./data/Visual_att_row_keys.npy')\n",
    "    cat=fscore(embeddings,'./data/my_trevor_hardClusters.csv',num2elem)\n",
    "    print('Categorization (Fscore rate) is '+str(cat))\n",
    "    \n",
    "    \n",
    "def unormc(X0):\n",
    "    X=X0.clone()\n",
    "    # normalize to unit norm\n",
    "    nrm=np.zeros(X.size()[0])\n",
    "    for i in range(0,X.size()[0]):\n",
    "        nrm[i]=np.sqrt(sum(X[i,:]**2))\n",
    "        if nrm[i] is not 0:\n",
    "            X[i,:]=X[i,:]/nrm[i]\n",
    "            \n",
    "    # center\n",
    "    mv = X.mean(axis=0)\n",
    "    for i in range(0,X.size()[0]):\n",
    "        X[i,:]=X[i,:] - mv\n",
    "    return X, nrm, mv\n",
    "\n",
    "def evaluate_norm(embeddings):\n",
    "#EVALUATE\n",
    "    df_simil_rates = pd.read_csv('./data/similarity-ratings.tsv',sep='\\t')\n",
    "    num2elem=np.load('./data/Visual_att_row_keys.npy')\n",
    "    ele2num = {a:b for b,a in enumerate(num2elem)}\n",
    "\n",
    "    emb_n,_,_ = unormc(embeddings)\n",
    "    sem_t,p=rho(df_simil_rates,ele2num,emb_n,'semantic')\n",
    "    print('Semantic similarity is '+str(sem_t))\n",
    "    \n",
    "    sem_v,p=rho(df_simil_rates,ele2num,emb_n,'visual')\n",
    "    print('Visual similarity is   '+str(sem_v))\n",
    "    return sem_t, sem_v\n",
    "\n",
    "def reduce_to_short(RMAT):\n",
    "    num_to_elem=np.load('./data/Visual_att_row_keys.npy')\n",
    "#    ele_to_num = {a:b for b,a in enumerate(num_to_elem)}\n",
    "#    num_to_elem_reduced=[]\n",
    "    vis_vec=RMAT\n",
    "    vis_vec_reduced=[]\n",
    "    with open('./data/mariella_mcrae_wordpairs.txt','r') as w:\n",
    "        k=0\n",
    "        for l in num_to_elem:\n",
    "            is_there = False\n",
    "            w.seek(0, 0)\n",
    "            for line in w:\n",
    "                words = line.split(\"#\")\n",
    "                #check if this pair is in df_simil_rates\n",
    "                #print(l,words[0],words[1][:-1])\n",
    "                #if so copy it to another file\n",
    "                if (words[0]== l or  words[1][:-1] == l) :\n",
    "                    is_there = True\n",
    "#                    num_to_elem_reduced.append(l)\n",
    "                    if k==0:\n",
    "                        vis_vec_reduced=vis_vec[k:k+1][:]\n",
    "                    else:\n",
    "                        vis_vec_reduced=np.concatenate((vis_vec_reduced,vis_vec[k:k+1]),axis=0)\n",
    "                    break\n",
    "            k+=1\n",
    "    return vis_vec_reduced\n",
    "\n",
    "def evaluate_short(embeddings):\n",
    "#EVALUATE\n",
    "    df_simil_rates = pd.read_csv('./data/short_similarity-ratings.tsv',sep='\\t')\n",
    "    num2elem=np.load('Visual_att_row_keys_short.npy')\n",
    "    ele2num = {a:b for b,a in enumerate(num2elem)}\n",
    "\n",
    "    sem,p=rho(df_simil_rates,ele2num,embeddings,'semantic')\n",
    "    print('Semantic similarity is '+str(sem))\n",
    "    \n",
    "    sem,p=rho(df_simil_rates,ele2num,embeddings,'visual')\n",
    "    print('Visual similarity is '+str(sem))\n",
    "    \n",
    "def evaluate_norm_short(embeddings):\n",
    "#EVALUATE\n",
    "    df_simil_rates = pd.read_csv('./data/short_similarity-ratings.tsv',sep='\\t')\n",
    "    num2elem=np.load('./data/Visual_att_row_keys_short.npy')\n",
    "    ele2num = {a:b for b,a in enumerate(num2elem)}\n",
    "\n",
    "    emb_n,_,_ = unormc(embeddings)\n",
    "    sem_t,p=rho(df_simil_rates,ele2num,emb_n,'semantic')\n",
    "    print('Semantic similarity is '+str(sem_t))\n",
    "    \n",
    "    sem_v,p=rho(df_simil_rates,ele2num,emb_n,'visual')\n",
    "    print('Visual similarity is   '+str(sem_v))\n",
    "    return sem_t, sem_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.param2 = kwargs[\"param2\"]\n",
    "        self.aa = kwargs[\"aa\"]\n",
    "        self.niter = kwargs[\"niter\"]\n",
    "        self.LR = kwargs[\"LR\"]\n",
    "        self.NCL = kwargs[\"NCL\"]\n",
    "        self.Cdamp = kwargs[\"Cdamp\"]\n",
    "\n",
    "    def forward(self,Xi,Go,Gi):\n",
    "        \n",
    "        #--- 1 graph embedding update\n",
    "        Xi.requires_grad=True\n",
    "        Xi=GD_torch_biW(Xi,Go,Gi,self.param2,self.aa,self.niter,self.LR)\n",
    "        Xi=Xi.detach().clone()\n",
    "        Xi = norm11(Xi.T).double().T\n",
    "\n",
    "        #--- 2 graph structure update: semantic prior\n",
    "        kmeans = KMeans(n_clusters=self.NCL, random_state=0, init='k-means++').fit(Xi.cpu().numpy())\n",
    "        CC0=torch.tensor([kmeans.labels_]).transpose(1,0) #estimate semantic communities\n",
    "\n",
    "        CIM = class_sim_torch(CC0).to(device)\n",
    "        CIM = (CIM==0).double() + self.Cdamp*(CIM!=0).double()\n",
    "        #Gi=Gi*CIM #encode semantic similarity in graph \n",
    "        #return Xi,Gi\n",
    "        return Xi,CIM\n",
    "\n",
    "class DGE_leapfrog(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.param2 = kwargs[\"param2\"]\n",
    "        self.aa = kwargs[\"aa\"]\n",
    "        self.cc = kwargs[\"cc\"]\n",
    "        self.niter = kwargs[\"niter\"]\n",
    "        self.LR = kwargs[\"LR\"]\n",
    "        self.NCL = kwargs[\"NCL\"]\n",
    "        self.Cdamp = kwargs[\"Cdamp\"]\n",
    "\n",
    "    def forward(self,Xi,Go,Gi,Giext):\n",
    "        \n",
    "        #--- 1 graph embedding update\n",
    "        Xi.requires_grad=True\n",
    "        Xi=GD_torch_triW(Xi,Go,Gi,Giext,self.param2,self.aa,self.cc,self.niter,self.LR)\n",
    "        Xi=Xi.detach().clone()\n",
    "        Xi = norm11(Xi.T).double().T\n",
    "\n",
    "        #--- 2 graph structure update: semantic prior\n",
    "        kmeans = KMeans(n_clusters=self.NCL, random_state=0, init='k-means++').fit(Xi.cpu().numpy())\n",
    "        CC0=torch.tensor([kmeans.labels_]).transpose(1,0) #estimate semantic communities\n",
    "\n",
    "        CIM = class_sim_torch(CC0).to(device)\n",
    "        CIM = (CIM==0).double() + self.Cdamp*(CIM!=0).double()\n",
    "        #Gi=Gi*CIM #encode semantic similarity in graph \n",
    "        #return Xi,Gi\n",
    "        return Xi,CIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Import modules\n",
    "from cdist import distx_fun, cosdist\n",
    "from similarity import simz_fun, simz_fun_sym\n",
    "from pca import PCA\n",
    "from normalize import norm01,norm11,class_sim_torch\n",
    "#from loss import sim_grad_descent_autograd, sim_grad_descent_biW_autograd\n",
    "#from loss import sim_grad_descent_biW_softmax_autograd\n",
    "from loss import X_entropy, GD_torch, GD_torch_biW, GD_torch_triW\n",
    "from cross_entropy import my_softmax\n",
    "from graph import data, data_textual, data_sg\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn.functional as FTR\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "OUT_PATH = '/Users/hwendt/Dropbox/SHARED_HWMD_UNSHARED/DGE_multimodal/DGE_results/'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if 0:\n",
    "    # IMPORT DATA!\n",
    "    Xo1 = data() #initial features matrix (this is used as regularization)\n",
    "    #Xo1=torch.tensor(Xo1).type(torch.FloatTensor).to(device)\n",
    "    Xo1=torch.tensor(Xo1).type(torch.DoubleTensor).to(device)\n",
    "    print(Xo1.shape) \n",
    "    N2,d2=Xo1.shape\n",
    "\n",
    "    Xo2 = data_textual(); sgstr = '' #initial features matrix (this is used as regularization)\n",
    "    Xo2 = data_sg(); sgstr = 'sg_' #initial features matrix (this is used as regularization)\n",
    "\n",
    "    #Xo2=torch.tensor(Xo2).type(torch.FloatTensor).to(device)\n",
    "    Xo2=torch.tensor(Xo2).type(torch.DoubleTensor).to(device)\n",
    "    print(Xo2.shape) \n",
    "    N2,d2=Xo2.shape\n",
    "\n",
    "    #Xo2short=reduce_to_short(Xo2)\n",
    "    #print(Xo2short.shape) \n",
    "\n",
    "    Xo3 = data_textual(); Xo3= torch.tensor(Xo3).type(torch.DoubleTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NORMINIT=0\n",
    "\n",
    "start = time.time()\n",
    "# VISUAL\n",
    "#Hyper-parameters\n",
    "d_emb=15#dimension embedding (small improve visual simiarity at the beginning)\n",
    "#d_emb=20#dimension embedding (small improve visual simiarity at the beginning)\n",
    "param11,param21=0.001,0.08 #l #smaller is not good\n",
    "niter_e=500\n",
    "LR10=1e-3\n",
    "\n",
    "d_emb=15\n",
    "param11,param21=0.0011,0.095 #l #smaller is not good\n",
    "niter_e=1000\n",
    "LR10=0.0004\n",
    "\n",
    "if 0:\n",
    "    #######################################################\n",
    "    #--- PART 1: Reference graph initialization\n",
    "    Go1 = simz_fun_sym(cosdist(Xo1),param11)\n",
    "\n",
    "    #######################################################\n",
    "    #--- PART 2: Graph embedding initialization\n",
    "    LF, X = PCA(Xo1,d_emb) # PCA\n",
    "    X = norm11(X.T).double().T\n",
    "\n",
    "    # initialize embedding features\n",
    "    X.requires_grad=True \n",
    "    X_o1 = GD_torch(X,Go1,param21,niter_e,LR10).detach()\n",
    "\n",
    "\n",
    "    if NORMINIT==1:\n",
    "        X_o1 = norm11(X_o1.T).double().T\n",
    "        norstr='_nor'\n",
    "    else:\n",
    "        norstr=''\n",
    "\n",
    "    G_o1 = simz_fun_sym(cosdist(X_o1),param21)\n",
    "\n",
    "    evaluate_norm_short(torch.tensor(reduce_to_short(X_o1)).type(torch.DoubleTensor).to(device))\n",
    "\n",
    "    plt.imshow(G_o1.cpu()), #print(G_o1.min(),G_o1.max(),G_o1.mean(),G_o1.std())\n",
    "\n",
    "    np.save(OUT_PATH + norstr +'vis_init.npy', X_o1)\n",
    "\n",
    "    print(\"elapsed time: \" +  str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# TEXTUAL\n",
    "#Hyper-parameters\n",
    "param12,param22=0.01,0.1\n",
    "niter_e=1000\n",
    "LR2=1e-3\n",
    "\n",
    "param12,param22=0.0125,0.125\n",
    "niter_e=1000\n",
    "LR2=4e-3\n",
    "\n",
    "if 0:\n",
    "    #######################################################\n",
    "    #--- PART 1: Reference graph initialization\n",
    "    Go2 = simz_fun_sym(cosdist(Xo2),param12)\n",
    "\n",
    "    #######################################################\n",
    "    #--- PART 2: Graph embedding initialization\n",
    "    LF, X = PCA(Xo2,d_emb) # PCA\n",
    "    X = norm11(X.T).double().T\n",
    "\n",
    "    # initialize embedding features\n",
    "    X.requires_grad=True \n",
    "    X_o2 = GD_torch(X,Go2,param22,niter_e,LR2).detach()\n",
    "\n",
    "    if NORMINIT==1:\n",
    "        X_o2 = norm11(X_o2.T).double().T\n",
    "    G_o2 = simz_fun_sym(cosdist(X_o2),param22)\n",
    "\n",
    "\n",
    "    evaluate_norm_short(torch.tensor(reduce_to_short(X_o2)).type(torch.DoubleTensor).to(device))\n",
    "\n",
    "    plt.imshow(G_o2.cpu()), print(G_o2.min(),G_o2.max(),G_o2.mean(),G_o2.std())\n",
    "\n",
    "    print(\"****************** VISUAL+TEXTUAL after initialization & normalization ****************** \")\n",
    "\n",
    "    evaluate_norm_short(torch.tensor(reduce_to_short(torch.cat((X_o1,X_o2),axis=1))).type(torch.DoubleTensor).to(device))\n",
    "\n",
    "    np.save(OUT_PATH + sgstr +norstr +  'text_init.npy', X_o2)\n",
    "    np.save(OUT_PATH + sgstr +norstr + 'vis_text_init.npy', torch.cat((X_o1,X_o2),axis=1))\n",
    "    print(\"elapsed time: \" +  str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Semantic similarity is 0.7781239700733908\n",
      "Visual similarity is   0.6419553329001694\n",
      "1\n",
      "Semantic similarity is 0.7781291407259504\n",
      "Visual similarity is   0.6424671745892889\n",
      "2\n",
      "Semantic similarity is 0.7781320592944736\n",
      "Visual similarity is   0.6430729021437915\n",
      "3\n",
      "Semantic similarity is 0.7780948287068202\n",
      "Visual similarity is   0.6436809574618543\n",
      "4\n",
      "Semantic similarity is 0.7779166219128035\n",
      "Visual similarity is   0.644178552758396\n",
      "5\n",
      "Semantic similarity is 0.7777344745931789\n",
      "Visual similarity is   0.6446372045041348\n",
      "6\n",
      "Semantic similarity is 0.7774774050137113\n",
      "Visual similarity is   0.644996550111322\n",
      "7\n",
      "Semantic similarity is 0.7772489955811169\n",
      "Visual similarity is   0.6453555555768176\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec0e4adc78f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mXis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_to_short\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_norm_short\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;31m#np.save(OUT_PATH + sgstr  + norstr + 'postembed_d15_it' +str(nDGE) +'_' +str(K) +'.npy', Xi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnDGE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" --- elapsed time: \"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-11114d91bd9a>\u001b[0m in \u001b[0;36mevaluate_norm_short\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0memb_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munormc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0msem_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_simil_rates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mele2num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'semantic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Semantic similarity is '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msem_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-11114d91bd9a>\u001b[0m in \u001b[0;36mrho\u001b[0;34m(dataframe, elem_num, embeddings, rtype)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Finally, we calculate Spearman's rho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melem_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melem_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#Calculate d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'semantic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-11114d91bd9a>\u001b[0m in \u001b[0;36mupdate_df\u001b[0;34m(dataframe, elem_num, embeddings)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#n=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mword1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mword2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[0;31m# raise_missing is included for compat with the parent class signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2741\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2743\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2744\u001b[0m             )\n\u001b[1;32m   2745\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   3005\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectValuesExtensionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_interval_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIntervalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__from_arrow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load joint DGE embedding results for textual and visual and embedd in one single graph\n",
    "\n",
    "start = time.time()\n",
    "import random\n",
    "random.seed=1979\n",
    "torch.manual_seed=1979\n",
    "torch.cuda.manual_seed=1979\n",
    "\n",
    "niter = 1#2*250\n",
    "N_iter_G = 5\n",
    "LR = 1e-4\n",
    "a_mix = 0.5\n",
    "a_mix_0 = a_mix\n",
    "\n",
    "param2 = 16*0.125 * (param21 + param22)\n",
    "\n",
    "sgstr = 'sg_'; s1=3\n",
    "#sgstr = ''; s1=4\n",
    "norstr='_nor'\n",
    "#NSTR=''\n",
    "\n",
    "\n",
    "KK=20\n",
    "\n",
    "if s1==3:\n",
    "    param2=0.3 \n",
    "    LR1=0.001 \n",
    "    niter_g1=5\n",
    "    NCL1=20\n",
    "    aa1=0.05 \n",
    "    Cdamp1=0.7 \n",
    "\n",
    "if s1==4:\n",
    "    param2=0.3 \n",
    "    LR1=0.001 \n",
    "    niter_g1=4 \n",
    "    NCL1=6 \n",
    "    aa1=0.1 \n",
    "    Cdamp1=0.7 \n",
    "\n",
    "#model1 = DGE_leapfrog(param2=param21,aa=aa1,niter=niter_g1,LR=LR1,NCL=NCL1,cc=cc1,Cdamp=Cdamp1)\n",
    "model1 = DGE(param2=param21,aa=aa1,niter=niter_g1,LR=LR1,NCL=NCL1,Cdamp=Cdamp1)\n",
    "\n",
    "P = []\n",
    "start = time.time()\n",
    "for nDGE in range(s1,s1+1):\n",
    "    Xi1 = torch.tensor(np.load(OUT_PATH + sgstr  + norstr + 'text_d15_2_cc12_it' +str(nDGE) +'.npy'))\n",
    "    Xi2 = torch.tensor(np.load(OUT_PATH + sgstr  + norstr + 'vis_d15_2_cc12_it' +str(nDGE) +'.npy'))\n",
    "    \n",
    "#    print( sgstr  + norstr + 'text_d15_2_cc12_it' +str(nDGE) +'.npy')\n",
    "#    print( sgstr  + norstr + 'vis_d15_2_cc12_it' +str(nDGE) +'.npy')\n",
    "    \n",
    "    \n",
    "    Gi1=simz_fun_sym(cosdist(Xi1),param21)\n",
    "    Gi2=simz_fun_sym(cosdist(Xi2),param22)\n",
    "    \n",
    "    #Xi=a_mix_0 * torch.tensor(Xi1).detach().clone() + (1-a_mix_0) * torch.tensor(Xi2).detach().clone()\n",
    "    Xi=torch.cat((Xi1.to(\"cpu\"),Xi2.to(\"cpu\")),axis=1)\n",
    "    Gi0=simz_fun_sym(cosdist(Xi),param2); Gi=Gi0\n",
    "    Xi.requires_grad=True\n",
    "    \n",
    "    for K in range(KK):\n",
    "#        Xi,CIM1 = model1(Xi,Gi1,Gi2); Gi1=Gi1*CIM1; Gi2=Gi2*CIM1\n",
    "        Xi,CIM = model1(Xi,Gi,Gi0); Gi=Gi*CIM\n",
    "        \n",
    "        Xi=Xi.detach().clone()\n",
    "        Xi = norm11(Xi.T).double().T\n",
    "        np.save(OUT_PATH + sgstr  + norstr + 'postembed_d15_it' +str(nDGE) +'_' +str(K) +'.npy', Xi)\n",
    "        Xis=torch.tensor(reduce_to_short(Xi.to(\"cpu\"))).type(torch.DoubleTensor)\n",
    "        print(K)\n",
    "        P.append(evaluate_norm_short(Xis))\n",
    "        #np.save(OUT_PATH + sgstr  + norstr + 'postembed_d15_it' +str(nDGE) +'_' +str(K) +'.npy', Xi)\n",
    "    print(str(nDGE) + \" --- elapsed time: \" +  str(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
